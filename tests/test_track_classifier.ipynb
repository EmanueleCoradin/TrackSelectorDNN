{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming your model code is in ../models/\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.track_classifier import TrackClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTrackDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generates random hit-level data grouped by track.\n",
    "    Each track has 5–15 hits, each hit has `hit_input_dim` features.\n",
    "    Each track also has `track_feat_dim` features and a binary label.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_tracks=2000, hit_input_dim=8, track_feat_dim=4, max_hits=15):\n",
    "        super().__init__()\n",
    "        self.hit_input_dim = hit_input_dim\n",
    "        self.track_feat_dim = track_feat_dim\n",
    "\n",
    "        self.tracks = []\n",
    "        self.hits = []\n",
    "        self.batch_idx = []\n",
    "        self.labels = []\n",
    "\n",
    "        for track_id in range(n_tracks):\n",
    "            n_hits = np.random.randint(5, max_hits)\n",
    "            hits = np.random.randn(n_hits, hit_input_dim).astype(np.float32)\n",
    "            track_feats = np.random.randn(track_feat_dim).astype(np.float32)\n",
    "            label = np.random.randint(0, 2)\n",
    "\n",
    "            self.hits.append(hits)\n",
    "            self.tracks.append(track_feats)\n",
    "            self.labels.append(label)\n",
    "            self.batch_idx.append(np.full(n_hits, track_id, dtype=np.int64))\n",
    "\n",
    "        # Flatten for convenience\n",
    "        self.all_hits = np.concatenate(self.hits, axis=0)\n",
    "        self.all_batch_idx = np.concatenate(self.batch_idx, axis=0)\n",
    "        self.all_tracks = np.stack(self.tracks, axis=0)\n",
    "        self.all_labels = np.array(self.labels, dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tracks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return per-track aggregated view\n",
    "        mask = self.all_batch_idx == idx\n",
    "        return (\n",
    "            torch.tensor(self.all_hits[mask]),\n",
    "            torch.tensor(self.all_tracks[idx]),\n",
    "            torch.tensor(idx),\n",
    "            torch.tensor(self.all_labels[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    hits, tracks, batch_ids, labels = zip(*batch)\n",
    "    hit_features = torch.cat(hits, dim=0)\n",
    "    track_features = torch.stack(tracks, dim=0)\n",
    "    batch_indices = torch.cat([\n",
    "        torch.full((len(h),), i, dtype=torch.long)\n",
    "        for i, h in enumerate(hits)\n",
    "    ])\n",
    "    labels = torch.stack(labels).float()\n",
    "    return hit_features, track_features, batch_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DummyTrackDataset(n_tracks=500)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyTrackDataset' object has no attribute '__get_item__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_item__\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DummyTrackDataset' object has no attribute '__get_item__'"
     ]
    }
   ],
   "source": [
    "train_dataset.__get_item__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TrackClassifier(\n",
    "    hit_input_dim=8,\n",
    "    track_feat_dim=4,\n",
    "    latent_dim=16,\n",
    "    pooling_type=\"sum\",\n",
    "    netA_hidden_dim=32,\n",
    "    netA_hidden_layers=2,\n",
    "    netB_hidden_dim=64,\n",
    "    netB_hidden_layers=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16/16 [00:00<00:00, 32.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.7055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16/16 [00:00<00:00, 146.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss = 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16/16 [00:00<00:00, 145.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss = 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 134.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss = 0.6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16/16 [00:00<00:00, 147.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss = 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for hit_features, track_features, batch_indices, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        hit_features = hit_features.to(device)\n",
    "        track_features = track_features.to(device)\n",
    "        batch_indices = batch_indices.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(hit_features, track_features, batch_indices)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(labels)\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}: loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.19669943 0.27244458 0.5054557  0.8087572  0.37896484 0.41168737\n",
      " 0.5854193  0.5592062  0.4110257  0.28873017]\n",
      "Labels: [0. 0. 1. 1. 1. 0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    hit_features, track_features, batch_indices, labels = next(iter(train_loader))\n",
    "    hit_features, track_features, batch_indices = (\n",
    "        hit_features.to(device), track_features.to(device), batch_indices.to(device)\n",
    "    )\n",
    "    preds = model(hit_features, track_features, batch_indices)\n",
    "    print(\"Predictions:\", preds[:10].cpu().numpy())\n",
    "    print(\"Labels:\", labels[:10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_features, track_features, batch_indices, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([294, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([294])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "         3,  3,  3,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,\n",
       "         9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19,\n",
       "        19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
       "        21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26,\n",
       "        26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28,\n",
       "        28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        31, 31, 31, 31, 31, 31])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
