{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac6e79f-cfaf-4f03-bc18-8e3f66f08e61",
   "metadata": {},
   "source": [
    "# Read and Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c02335-9669-46ee-8f05-facd09c5588e",
   "metadata": {},
   "source": [
    "## import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d39972-80f9-4d1b-9e14-a806f300bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from TrackSelectorDNN.data_manager.dataset import TrackDatasetFromFile\n",
    "from trackkit import preprocessing as pre\n",
    "from trackkit import plotting as plot\n",
    "from trackkit import summary as summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37be5d-3a92-4a47-9f33-6221d30346bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH  = \"/shared/data/100_tracks_skip-connections_dataset.root\"\n",
    "OUTPUT_PATH = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/100_tracks_train-val_dataset_skip-connections.pt\"\n",
    "OUTPUT_PATH_TRAIN = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/100_tracks_train_dataset_skip-connections.pt\"\n",
    "OUTPUT_PATH_VAL  = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/100_tracks_val_dataset_skip-connections.pt\"\n",
    "MAX_HITS = 16\n",
    "\n",
    "LOW_PERCENTILE  = 0.001\n",
    "HIGH_PERCENTILE = 0.999\n",
    "EPSILON = 1.e-8\n",
    "\n",
    "# For the preselector\n",
    "\n",
    "ONE_HOT_CONFIG = {\n",
    "    \"hltPixelTrack_nPixelHits\": [2, 3, 4, 5, 6],\n",
    "    \"hltPixelTrack_nTrkLays\":   [4, 5, 6, 7],\n",
    "    \"hltPixelTrack_ndof\":       [3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "# Continuous features used by the preselector (normalized)\n",
    "PRE_CONTINUOUS_FEATURES = [\n",
    "    \"hltPixelTrack_chi2\",\n",
    "    \"hltPixelTrack_eta\",\n",
    "    \"hltPixelTrack_vx\",\n",
    "    \"hltPixelTrack_vy\",\n",
    "    \"hltPixelTrack_dxyBS\",\n",
    "]\n",
    "\n",
    "\n",
    "#For the full DNN\n",
    "recHitBranches = [\n",
    "    \"hltPixelTrackRecHits_globalX\",\n",
    "    \"hltPixelTrackRecHits_globalY\",\n",
    "    \"hltPixelTrackRecHits_globalZ\",\n",
    "    \"hltPixelTrackRecHits_globalErrX\",\n",
    "    \"hltPixelTrackRecHits_globalErrY\",\n",
    "    \"hltPixelTrackRecHits_globalErrZ\",\n",
    "    \"hltPixelTrackRecHits_globalR\",\n",
    "    \"hltPixelTrackRecHits_globalEta\",\n",
    "    \"hltPixelTrackRecHits_globalPhi\"\n",
    "]\n",
    "\n",
    "recoPixelTrackBranches = [\n",
    "    \"hltPixelTrack_matched\",\n",
    "    \"hltPixelTrack_isHighPurity\",\n",
    "    \"hltPixelTrack_nPixelHits\",\n",
    "    \"hltPixelTrack_nTrkLays\",\n",
    "    \"hltPixelTrack_charge\",\n",
    "    \"hltPixelTrack_chi2\",\n",
    "    \"hltPixelTrack_dXY\",\n",
    "    \"hltPixelTrack_dZ\",\n",
    "    \"hltPixelTrack_dZError\",\n",
    "    \"hltPixelTrack_dsz\",\n",
    "    \"hltPixelTrack_dszErr\",\n",
    "    \"hltPixelTrack_dxyError\",\n",
    "    \"hltPixelTrack_eta\",\n",
    "    \"hltPixelTrack_etaErr\",\n",
    "    \"hltPixelTrack_lambdaErr\",\n",
    "    \"hltPixelTrack_ndof\",\n",
    "    \"hltPixelTrack_phi\",\n",
    "    \"hltPixelTrack_phiErr\",\n",
    "    \"hltPixelTrack_pt\",\n",
    "    \"hltPixelTrack_ptErr\",\n",
    "    \"hltPixelTrack_qoverp\",\n",
    "    \"hltPixelTrack_qoverpErr\",\n",
    "    \"hltPixelTrack_vx\",\n",
    "    \"hltPixelTrack_vy\",\n",
    "    \"hltPixelTrack_vz\",\n",
    "    \"hltPixelTrack_dzBS\",\n",
    "    \"hltPixelTrack_dxyBS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aeb75-2f4d-4f08-9ddc-816a844e2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_feature(x, values=None, cap=None):\n",
    "    \"\"\"\n",
    "    x: (N,) array\n",
    "    values: explicit categorical values\n",
    "    bins: explicit integer bins\n",
    "    cap: value above which everything goes to last bin\n",
    "    \"\"\"\n",
    "    if cap is not None:\n",
    "        x = np.minimum(x, cap)\n",
    "\n",
    "    if values is not None:\n",
    "        return np.stack([(x == v).astype(np.float32) for v in values], axis=1)\n",
    "\n",
    "    raise ValueError(\"Specify values or bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b6c5c-5a42-473c-8c19-b7a4b9264580",
   "metadata": {},
   "source": [
    "## Preprocess input features for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1f24c-8b90-409f-8a19-559888c2b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(INPUT_PATH)\n",
    "events = file[\"Events\"]\n",
    "data = events.arrays(library=\"ak\")\n",
    "\n",
    "recHitFeaturesList = []\n",
    "for b in recHitBranches:\n",
    "    arr = ak.to_numpy(ak.flatten(data[b])).reshape(-1,MAX_HITS)  # (n_tracks, MAX_HITS)\n",
    "    recHitFeaturesList.append(arr)\n",
    "\n",
    "recHitFeatures = np.stack(recHitFeaturesList, axis=2)  # (n_tracks, MAX_HITS, n_features)\n",
    "\n",
    "# Create mask (1 = real hit, 0 = padded)\n",
    "mask = np.isnan(recHitFeatures[:,:,0])  # (n_tracks, MAX_HITS)\n",
    "\n",
    "# Replace NaNs with 0.0\n",
    "recHitFeatures[mask] = 0\n",
    "isRecHit = ~mask\n",
    "\n",
    "recoPixelTrackList = []\n",
    "for b in recoPixelTrackBranches:\n",
    "    arr = ak.to_numpy(ak.flatten(data[b]))  # (n_tracks,)\n",
    "    recoPixelTrackList.append(arr)\n",
    "\n",
    "\n",
    "recoPixelTrackFeatures = np.stack(recoPixelTrackList[2:], axis=1)  # (n_tracks, n_features)\n",
    "recoPixelTrackLabels = np.array(recoPixelTrackList[0])\n",
    "recoPixelTrackIsHighPurity = np.array(recoPixelTrackList[1])\n",
    "recoPixelTrackFeatures_names = recoPixelTrackBranches[2:]  # skip 'hltPixelTrack_matched and IsHP' (label)\n",
    "\n",
    "mask_true = (recoPixelTrackLabels==1)\n",
    "mask_fake = (recoPixelTrackLabels==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b2630-19f6-474a-9953-acf16bf96869",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summ.summarize_features(recoPixelTrackFeatures, recoPixelTrackFeatures_names)\n",
    "summary_df = summ.print_summary_table(summary, sort_by=\"skew\", top=15)\n",
    "issues = summ.flag_outliers(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052c879-dc4b-4f3c-bad1-0eb43e45e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summ.summarize_features(recoPixelTrackFeatures, recoPixelTrackFeatures_names)\n",
    "summary_df = summ.print_summary_table(summary, sort_by=\"skew\", top=15)\n",
    "issues = summ.flag_outliers(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d55a4-805c-485c-8f6b-dfe1149d2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = recoPixelTrackLabels.shape[0]\n",
    "N_true = recoPixelTrackLabels.sum()\n",
    "N_fake = N - N_true\n",
    "\n",
    "w_true = N / (2 * N_true)\n",
    "w_fake = N / (2 * N_fake)\n",
    "\n",
    "print(w_true, w_fake)\n",
    "print(recoPixelTrackLabels.sum()/recoPixelTrackLabels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8da43-feff-4528-a13e-3aca434ad902",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_log_track = []\n",
    "# Variables to log-transform and clip\n",
    "log_vars = [\"hltPixelTrack_pt\", \"hltPixelTrack_ptErr\", \n",
    "            \"hltPixelTrack_dxyError\", \"hltPixelTrack_phiErr\", \n",
    "            \"hltPixelTrack_chi2\", \"hltPixelTrack_dszErr\",\n",
    "            \"hltPixelTrack_dZError\", \"hltPixelTrack_qoverpErr\", \"hltPixelTrack_lambdaErr\", \"hltPixelTrack_etaErr\"]\n",
    "\n",
    "recoPixelTrackFeatures_proc = recoPixelTrackFeatures.copy()\n",
    "for i, name in enumerate(recoPixelTrackFeatures_names):\n",
    "    do_log_track.append(name in log_vars)\n",
    "    if name in log_vars:\n",
    "        x = recoPixelTrackFeatures_proc[:, i]\n",
    "        x = np.log10(EPSILON+x)\n",
    "        recoPixelTrackFeatures_proc[:, i] = x\n",
    "clip_min_track = []\n",
    "clip_max_track = []\n",
    "# Variables to just clip\n",
    "clip_vars = [\n",
    "    \"hltPixelTrack_pt\", \"hltPixelTrack_ptErr\", \n",
    "    \"hltPixelTrack_dxyError\", \"hltPixelTrack_phiErr\", \n",
    "    \"hltPixelTrack_chi2\", \"hltPixelTrack_dszErr\",\n",
    "    \"hltPixelTrack_dZError\", \"hltPixelTrack_qoverpErr\", \"hltPixelTrack_lambdaErr\", \"hltPixelTrack_etaErr\",\n",
    "    \"hltPixelTrack_dXY\", \"hltPixelTrack_dsz\", \n",
    "    \"hltPixelTrack_vx\", \"hltPixelTrack_vy\"]\n",
    "\n",
    "for i, name in enumerate(recoPixelTrackFeatures_names):\n",
    "    if name in clip_vars:\n",
    "        x = recoPixelTrackFeatures_proc[:, i]\n",
    "        x, lo, hi = pre.clip_outliers(x, low=LOW_PERCENTILE, high=HIGH_PERCENTILE)\n",
    "        recoPixelTrackFeatures_proc[:, i] = x\n",
    "        clip_min_track.append(lo)\n",
    "        clip_max_track.append(hi)\n",
    "    else:\n",
    "        clip_min_track.append(np.nan)\n",
    "        clip_max_track.append(np.nan)\n",
    "\n",
    "recoPixelTrackFeaturesNorm, recoPixelTrack_mean, recoPixelTrack_std = pre.normalize_2d(recoPixelTrackFeatures_proc)\n",
    "summary_norm = summ.summarize_features(recoPixelTrackFeaturesNorm, recoPixelTrackFeatures_names)\n",
    "summary_norm_df = summ.print_summary_table(summary_norm, sort_by=\"skew\", top=15)\n",
    "issues = summ.flag_outliers(summary_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5a64c-6613-429b-b137-e4d47931b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_feature_distributions(\n",
    "    X_ref=recoPixelTrackFeaturesNorm,\n",
    "    feature_names=recoPixelTrackFeatures_names,\n",
    "    y=recoPixelTrackLabels,\n",
    "    labels=(\"Normalized recoTrack Features\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f899ca-50ae-44bc-a3dd-0487856e418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_recHits = summ.summarize_recHits(recHitFeatures, isRecHit, recHitBranches)\n",
    "summary_recHits_df = summ.print_summary_table(summary_recHits, sort_by=\"skew\", top=15)\n",
    "issues_recHits = summ.flag_outliers(summary_recHits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198446a-e8c7-4e28-a090-afa8ec3f8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_log_hit = []\n",
    "log_recHit_vars = [\"hltPixelTrackRecHits_globalR\", \"hltPixelTrackRecHits_globalErrX\", \"hltPixelTrackRecHits_globalErrY\", \"hltPixelTrackRecHits_globalErrZ\"]\n",
    "       \n",
    "recHitFeatures_proc = recHitFeatures.copy()\n",
    "for f, name in enumerate(recHitBranches):\n",
    "    do_log_hit.append(name in log_recHit_vars)\n",
    "    if name in log_recHit_vars:\n",
    "        print(f, name)\n",
    "        recHitFeatures_proc = pre.masked_log_transform(recHitFeatures_proc, isRecHit, f, eps=EPSILON, method='log_eps')\n",
    "\n",
    "recHitFeatures_norm, recHit_mean, recHit_std = pre.normalize_features_masked(recHitFeatures_proc, isRecHit, eps=EPSILON)\n",
    "clip_min_hit = [np.nan for i in enumerate(recHitBranches)]\n",
    "clip_max_hit = [np.nan for i in enumerate(recHitBranches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67591f81-cc48-46b0-8fdf-ec9bf2b17149",
   "metadata": {},
   "outputs": [],
   "source": [
    "recHitFeatures_norm_plot = np.array(pre.masked_flatten(recHitFeatures_norm, isRecHit)).T\n",
    "y_hits = np.repeat(recoPixelTrackLabels, isRecHit.sum(axis=1))  # only if you want to compare by label\n",
    "\n",
    "plot.plot_feature_distributions(\n",
    "    X_ref=recHitFeatures_norm_plot,\n",
    "    feature_names=recHitBranches,\n",
    "    y=y_hits,\n",
    "    labels=(\"Raw recHits\"),\n",
    "    n_cols=3,\n",
    "    bins=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc48aa-ab9f-446c-8b4b-6f614fb21f5c",
   "metadata": {},
   "source": [
    "## Preprocess input features for Preselector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09680e-e34e-4adb-8251-54acd66c67a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont_indices = [recoPixelTrackFeatures_names.index(n) for n in PRE_CONTINUOUS_FEATURES]\n",
    "X_cont = recoPixelTrackFeaturesNorm[:, cont_indices]\n",
    "onehot_blocks = []\n",
    "onehot_names  = []\n",
    "\n",
    "for name, values in ONE_HOT_CONFIG.items():\n",
    "    idx = recoPixelTrackFeatures_names.index(name)\n",
    "    oh = one_hot_encode_feature(recoPixelTrackFeatures[:, idx], values, cap=max(values))\n",
    "    onehot_blocks.append(oh)\n",
    "    onehot_names.extend([f\"{name}=={v}\" for v in values])\n",
    "\n",
    "X_onehot = np.concatenate(onehot_blocks, axis=1)\n",
    "\n",
    "# Final preselector input\n",
    "X_pre = np.concatenate([X_cont, X_onehot], axis=1)\n",
    "pre_names = PRE_CONTINUOUS_FEATURES + onehot_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d23cf-c741-4b7f-a40f-215e484f195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a669350-1580-4b9d-ab1c-5124884c1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_feature_distributions(\n",
    "    X_ref=X_pre,\n",
    "    feature_names=pre_names,\n",
    "    y=recoPixelTrackLabels,\n",
    "    labels=(\"Raw recHits\"),\n",
    "    n_cols=3,\n",
    "    bins=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d03ce6-205e-4dc6-8629-5bde78cad875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_2d(\n",
    "    X,\n",
    "    feature_names,\n",
    "    i,\n",
    "    j,\n",
    "    y=None,\n",
    "    max_points=100_000,\n",
    "    bins=100,\n",
    "    figsize=(5, 5),\n",
    "    density=True,\n",
    "    cmap_true=\"Blues\",\n",
    "    cmap_fake=\"Reds\",\n",
    "):\n",
    "    assert i < X.shape[1] and j < X.shape[1]\n",
    "\n",
    "    # Subsample for speed\n",
    "    N = X.shape[0]\n",
    "    if N > max_points:\n",
    "        idx = np.random.choice(N, max_points, replace=False)\n",
    "        X = X[idx]\n",
    "        if y is not None:\n",
    "            y = y[idx]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if y is None:\n",
    "        plt.hist2d(\n",
    "            X[:, i],\n",
    "            X[:, j],\n",
    "            bins=bins,\n",
    "            density=density,\n",
    "            cmap=\"viridis\",\n",
    "        )\n",
    "        plt.colorbar(label=\"Density\")\n",
    "    else:\n",
    "        mask_true = (y == 1)\n",
    "        mask_fake = (y == 0)\n",
    "\n",
    "        plt.hist2d(\n",
    "            X[mask_fake, i],\n",
    "            X[mask_fake, j],\n",
    "            bins=bins,\n",
    "            density=density,\n",
    "            cmap=cmap_fake,\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        plt.hist2d(\n",
    "            X[mask_true, i],\n",
    "            X[mask_true, j],\n",
    "            bins=bins,\n",
    "            density=density,\n",
    "            cmap=cmap_true,\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        plt.colorbar(label=\"Density\")\n",
    "\n",
    "    plt.xlabel(feature_names[i])\n",
    "    plt.ylabel(feature_names[j])\n",
    "    plt.title(f\"{feature_names[i]} vs {feature_names[j]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e0d95-8024-4aa5-8836-f099acb4d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_2d(\n",
    "    X_pre,\n",
    "    pre_names,\n",
    "    2, 4,\n",
    "    y=recoPixelTrackLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7553c0a-ca2b-4d3f-8789-173ba49e4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_2d(\n",
    "    recoPixelTrackFeatures,\n",
    "    recoPixelTrackBranches[2:],\n",
    "    13, 0,\n",
    "    y=recoPixelTrackLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418478cf-141f-4e36-88e0-c0b19eea2c23",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc243bc3-1dba-42c7-b7b6-8a925c964e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "recoPixelTrackBranches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284bfbc-0746-4aa2-8bbf-be77fc9da29b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    # --- Core datasets ---\n",
    "    \"recHitFeatures\": torch.tensor(recHitFeatures_norm, dtype=torch.float32),\n",
    "    \"isRecHit\": torch.tensor(isRecHit, dtype=torch.bool),\n",
    "    \"recoPixelTrackFeatures\": torch.tensor(recoPixelTrackFeaturesNorm, dtype=torch.float32),\n",
    "    \"labels\": torch.tensor(recoPixelTrackLabels, dtype=torch.float32),\n",
    "    \"isHighPurity\": torch.tensor(recoPixelTrackIsHighPurity, dtype=torch.bool),\n",
    "\n",
    "    # --- Normalization stats ---\n",
    "    \"recHit_mean\": torch.tensor(recHit_mean, dtype=torch.float32),\n",
    "    \"recHit_std\": torch.tensor(recHit_std, dtype=torch.float32),\n",
    "    \"recoPixelTrack_mean\": torch.tensor(recoPixelTrack_mean, dtype=torch.float32),\n",
    "    \"recoPixelTrack_std\": torch.tensor(recoPixelTrack_std, dtype=torch.float32),\n",
    "    \n",
    "    # --- Metadata ---\n",
    "    \"recHitBranches\": recHitBranches,\n",
    "    \"recoPixelTrackBranches\": recoPixelTrackBranches[2:],  # exclude label and isHP\n",
    "    \"MAX_HITS\": MAX_HITS,\n",
    "    \"EPSILON\": EPSILON,\n",
    "    \"LOW_PERCENTILE\": LOW_PERCENTILE,\n",
    "    \"HIGH_PERCENTILE\": HIGH_PERCENTILE,\n",
    "    \"log_vars\": log_vars,\n",
    "    \"clip_vars\": clip_vars,\n",
    "    \"log_recHit_vars\": log_recHit_vars,\n",
    "    \"do_log_hit\": torch.tensor(do_log_hit, dtype=torch.bool),\n",
    "    \"clip_min_hit\": torch.tensor(clip_min_hit, dtype=torch.float32),\n",
    "    \"clip_max_hit\": torch.tensor(clip_max_hit, dtype=torch.float32),\n",
    "    \"do_log_track\": torch.tensor(do_log_track, dtype=torch.bool),\n",
    "    \"clip_min_track\": torch.tensor(clip_min_track, dtype=torch.float32),\n",
    "    \"clip_max_track\": torch.tensor(clip_max_track, dtype=torch.float32),\n",
    "\n",
    "    # New preselector view\n",
    "    \"recoPixelTrackFeatures_pre\": torch.tensor(X_pre, dtype=torch.float32),\n",
    "    \"recoPixelTrackFeatures_pre_names\": pre_names,\n",
    "    \"recoPixelTrackFeatures_pre_is_onehot\": (\n",
    "        [False] * len(PRE_CONTINUOUS_FEATURES)\n",
    "        + [True] * X_onehot.shape[1]\n",
    "    ),\n",
    "\n",
    "    # Normalization stats (only for continuous features)\n",
    "    \"recoPixelTrack_pre_mean\": torch.tensor(recoPixelTrack_mean[..., cont_indices], dtype=torch.float32),\n",
    "    \"recoPixelTrack_pre_std\": torch.tensor(recoPixelTrack_std[..., cont_indices], dtype=torch.float32),\n",
    "}\n",
    "\n",
    "torch.save(save_dict, OUTPUT_PATH)\n",
    "print(f\"Saved preselector dataset to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6558b0e-83df-48f7-9b71-b9898f19ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.2\n",
    "dataset_len = len(save_dict[\"labels\"])\n",
    "val_len = int(dataset_len * val_fraction)\n",
    "train_len = dataset_len - val_len\n",
    "\n",
    "indices = torch.randperm(dataset_len, generator=torch.Generator().manual_seed(42))\n",
    "train_idx, val_idx = indices[:train_len], indices[train_len:]\n",
    "\n",
    "def subset_dict(save_dict, indices):\n",
    "    subset = {}\n",
    "    ref_len = save_dict[\"labels\"].shape[0]\n",
    "\n",
    "    for key, value in save_dict.items():\n",
    "        if torch.is_tensor(value) and value.shape[0] == ref_len:\n",
    "            subset[key] = value[indices]\n",
    "        else:\n",
    "            subset[key] = value\n",
    "\n",
    "    return subset\n",
    "\n",
    "train_dict = subset_dict(save_dict, train_idx)\n",
    "val_dict = subset_dict(save_dict, val_idx)\n",
    "\n",
    "torch.save(train_dict, OUTPUT_PATH_TRAIN)\n",
    "torch.save(val_dict, OUTPUT_PATH_VAL)\n",
    "print(f\"âœ… Saved train and validation datasets with metadata\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
