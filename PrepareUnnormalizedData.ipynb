{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dedb2e2-d054-4c53-baa5-1bc3eb62f059",
   "metadata": {},
   "source": [
    "# Read and prepare raw data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ee897-b23c-40e8-bda9-90d6bae6b1ea",
   "metadata": {},
   "source": [
    "## import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19465e4b-f8b5-467a-8b65-491b846994aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from TrackSelectorDNN.models.preprocessing import FeaturePreprocessing \n",
    "from torch.utils.data import random_split\n",
    "from TrackSelectorDNN.data_manager.dataset import TrackDatasetFromFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84732c16-a074-4482-b731-73ebbd07c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(x, eps=1e-8):\n",
    "    mean = np.mean(x, axis=(0, 1), keepdims=True)\n",
    "    std = np.std(x, axis=(0, 1), keepdims=True)\n",
    "    x_norm = (x - mean) / (std + eps)\n",
    "    return x_norm, mean, std\n",
    "\n",
    "def normalize_2d(x, eps=1e-8):\n",
    "    mean = np.nanmean(x, axis=0, keepdims=True)\n",
    "    std = np.nanstd(x, axis=0, keepdims=True)\n",
    "    return (x - mean) / (std + eps), mean, std\n",
    "    \n",
    "def summarize_features(X, recoPixelTrackFeatures_names):\n",
    "    summary = []\n",
    "    for i, name in enumerate(recoPixelTrackFeatures_names):\n",
    "        x = X[:, i]\n",
    "        x_clean = x[~np.isnan(x)]\n",
    "        min_val = np.min(x_clean)\n",
    "        max_val = np.max(x_clean)\n",
    "        mean_val = np.mean(x_clean)\n",
    "        std_val = np.std(x_clean)\n",
    "        zero_frac = np.sum(np.isclose(x_clean, 0)) / len(x_clean)\n",
    "        nan_frac = np.sum(np.isnan(x)) / len(x)\n",
    "        s = skew(x_clean)\n",
    "        summary.append({\n",
    "            \"feature\": name,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "            \"mean\": mean_val,\n",
    "            \"std\": std_val,\n",
    "            \"zeros(%)\": 100*zero_frac,\n",
    "            \"NaNs(%)\": 100*nan_frac,\n",
    "            \"skew\": s\n",
    "        })\n",
    "    return summary\n",
    "\n",
    "def print_summary_table(summary, sort_by=\"skew\", top=10):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(summary)\n",
    "    df_sorted = df.sort_values(by=sort_by, key=lambda x: np.abs(x), ascending=False)\n",
    "    print(df_sorted.head(top).to_string(index=False))\n",
    "    return df_sorted\n",
    "\n",
    "def flag_outliers(summary, std_threshold=100, skew_threshold=5, zero_frac_threshold=80):\n",
    "    issues = []\n",
    "    for row in summary:\n",
    "        if np.isnan(row[\"std\"]) or row[\"std\"] == 0:\n",
    "            issues.append((row[\"feature\"], \"Constant or NaN std\"))\n",
    "        if abs(row[\"skew\"]) > skew_threshold:\n",
    "            issues.append((row[\"feature\"], f\"Highly skewed ({row['skew']:.2f})\"))\n",
    "        if row[\"zeros(%)\"] > zero_frac_threshold:\n",
    "            issues.append((row[\"feature\"], f\"Mostly zeros ({row['zeros(%)']:.1f}%)\"))\n",
    "        if abs(row[\"max\"] - row[\"min\"]) > std_threshold * row[\"std\"]:\n",
    "            issues.append((row[\"feature\"], \"Extreme outlier range\"))\n",
    "    print(\"\\n Potentially problematic features:\")\n",
    "    for f, msg in issues:\n",
    "        print(f\" - {f:30s}: {msg}\")\n",
    "    return issues\n",
    "\n",
    "def clip_outliers(x, low=0.001, high=0.999):\n",
    "    lo, hi = np.percentile(x, [100*low, 100*high])\n",
    "    return np.clip(x, lo, hi), lo, hi\n",
    "\n",
    "def plot_feature_distributions(\n",
    "    X_ref,\n",
    "    feature_names,\n",
    "    y=None,\n",
    "    X_cmp=None,\n",
    "    labels=(\"Reference\", \"Comparison\"),\n",
    "    n_cols=4,\n",
    "    bins=50,\n",
    "    figsize=(16, 12),\n",
    "    density=True,\n",
    "    alpha_ref=0.6,\n",
    "    alpha_cmp=0.4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot feature distributions for one or two datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_ref : np.ndarray\n",
    "        Reference dataset of shape (n_samples, n_features).\n",
    "    feature_names : list of str\n",
    "        Names of the features to plot.\n",
    "    y : np.ndarray, optional\n",
    "        Binary labels (True/False or 1/0). If given, separate histograms by class.\n",
    "    X_cmp : np.ndarray, optional\n",
    "        Comparison dataset (same shape as X_ref) to overlay.\n",
    "    labels : tuple(str, str)\n",
    "        Labels for the legend corresponding to (X_ref, X_cmp).\n",
    "    n_cols : int\n",
    "        Number of subplot columns.\n",
    "    bins : int\n",
    "        Number of histogram bins.\n",
    "    figsize : tuple\n",
    "        Overall figure size.\n",
    "    density : bool\n",
    "        Whether to normalize histograms to density.\n",
    "    alpha_ref : float\n",
    "        Transparency for reference histograms.\n",
    "    alpha_cmp : float\n",
    "        Transparency for comparison histograms.\n",
    "    \"\"\"\n",
    "\n",
    "    n_features = X_ref.shape[1]\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for i, name in enumerate(feature_names):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # Determine plotting mode\n",
    "        if y is not None:\n",
    "            mask_true = (y == 1)\n",
    "            mask_fake = (y == 0)\n",
    "            plt.hist(\n",
    "                X_ref[mask_true, i], bins=bins, alpha=alpha_ref,\n",
    "                label=f\"{labels[0]} True\", density=density\n",
    "            )\n",
    "            plt.hist(\n",
    "                X_ref[mask_fake, i], bins=bins, alpha=alpha_ref,\n",
    "                label=f\"{labels[0]} Fake\", density=density\n",
    "            )\n",
    "            if X_cmp is not None:\n",
    "                plt.hist(\n",
    "                    X_cmp[mask_true, i], bins=bins, alpha=alpha_cmp,\n",
    "                    label=f\"{labels[1]} True\", density=density, linestyle=\"dashed\"\n",
    "                )\n",
    "                plt.hist(\n",
    "                    X_cmp[mask_fake, i], bins=bins, alpha=alpha_cmp,\n",
    "                    label=f\"{labels[1]} Fake\", density=density, linestyle=\"dashed\"\n",
    "                )\n",
    "        else:\n",
    "            plt.hist(X_ref[:, i], bins=bins, alpha=alpha_ref, label=labels[0], density=density)\n",
    "            if X_cmp is not None:\n",
    "                plt.hist(X_cmp[:, i], bins=bins, alpha=alpha_cmp, label=labels[1], density=density)\n",
    "\n",
    "        plt.title(name, fontsize=8)\n",
    "        plt.tick_params(axis=\"x\", labelsize=7)\n",
    "        plt.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(fontsize=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f632dd-e516-442f-aa4d-ae6df4c55d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT_PATH = \"ext.root\"\n",
    "INPUT_PATH  = \"/shared/data/100_tracks_train_dataset.root\"\n",
    "\n",
    "PREPROCESS_PATH = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_train-val_dataset_extended.pt\"\n",
    "PREPROCESS_PATH_TRAIN = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_train_dataset_extended.pt\"\n",
    "PREPROCESS_PATH_VAL = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_val_dataset_extended.pt\"\n",
    "\n",
    "OUTPUT_PATH = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_train-val_dataset_inference.pt\"\n",
    "OUTPUT_PATH_TRAIN = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_train_dataset_inference.pt\"\n",
    "OUTPUT_PATH_VAL  = \"/eos/user/e/ecoradin/GitHub/TrackSelectorDNN/TrackSelectorDNN/data/tracks_val_dataset_inference.pt\"\n",
    "MAX_HITS = 16\n",
    "\n",
    "LOW_PERCENTILE  = 0.001\n",
    "HIGH_PERCENTILE = 0.999\n",
    "EPSILON = 1.e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e70d2f-51ae-43ca-9c66-8624fdd24dd6",
   "metadata": {},
   "source": [
    "## Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab233e-193e-4a02-97d3-c236684fb355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the ROOT file\n",
    "file = uproot.open(INPUT_PATH)\n",
    "print(file.keys())\n",
    "\n",
    "print(\"\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "# Access the Events TTree\n",
    "events = file[\"Events\"]\n",
    "\n",
    "# List branches in Events\n",
    "print(\"Branches in Events:\")\n",
    "\n",
    "for branch in events.keys():\n",
    "# Inspect first few entries\n",
    "    print(\"   -\", branch)\n",
    "\n",
    "# Read all branches into an awkward array\n",
    "data = events.arrays(library=\"ak\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b8487-2353-465a-98f9-773b08787d4c",
   "metadata": {},
   "source": [
    "Decide which branches contain either input features or output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eadb1e8-4d52-4ad0-ac4d-82e559a095cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recHitBranches = [\n",
    "    \"hltPixelTrackRecHits_globalX\",\n",
    "    \"hltPixelTrackRecHits_globalY\",\n",
    "    \"hltPixelTrackRecHits_globalZ\",\n",
    "    \"hltPixelTrackRecHits_globalErrX\",\n",
    "    \"hltPixelTrackRecHits_globalErrY\",\n",
    "    \"hltPixelTrackRecHits_globalErrZ\",\n",
    "    \"hltPixelTrackRecHits_globalR\",\n",
    "    \"hltPixelTrackRecHits_globalEta\",\n",
    "    \"hltPixelTrackRecHits_globalPhi\"\n",
    "]\n",
    "\n",
    "recoPixelTrackBranches = [\n",
    "    \"hltPixelTrack_matched\",\n",
    "    \"hltPixelTrack_isHighPurity\",\n",
    "    \"hltPixelTrack_nPixelHits\",\n",
    "    \"hltPixelTrack_nTrkLays\",\n",
    "    \"hltPixelTrack_charge\",\n",
    "    \"hltPixelTrack_chi2\",\n",
    "    \"hltPixelTrack_dXY\",\n",
    "    \"hltPixelTrack_dZ\",\n",
    "    \"hltPixelTrack_dZError\",\n",
    "    \"hltPixelTrack_dsz\",\n",
    "    \"hltPixelTrack_dszErr\",\n",
    "    \"hltPixelTrack_dxyError\",\n",
    "    \"hltPixelTrack_eta\",\n",
    "    \"hltPixelTrack_etaErr\",\n",
    "    \"hltPixelTrack_lambdaErr\",\n",
    "    \"hltPixelTrack_ndof\",\n",
    "    \"hltPixelTrack_phi\",\n",
    "    \"hltPixelTrack_phiErr\",\n",
    "    \"hltPixelTrack_pt\",\n",
    "    \"hltPixelTrack_ptErr\",\n",
    "    \"hltPixelTrack_qoverp\",\n",
    "    \"hltPixelTrack_qoverpErr\",\n",
    "    \"hltPixelTrack_vx\",\n",
    "    \"hltPixelTrack_vy\",\n",
    "    \"hltPixelTrack_vz\",\n",
    "    \"hltPixelTrack_dzBS\",\n",
    "    \"hltPixelTrack_dxyBS\"\n",
    "]\n",
    "\n",
    "genPartBranches = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03795d83-e1f9-4ad7-9437-e178ca1070a1",
   "metadata": {},
   "source": [
    "Read the branches from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1e3f2-cb66-41db-a4db-4a4ee9e495b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Awkward arrays to (n_tracks, MAX_HITS) arrays and stack\n",
    "recHitFeaturesList = []\n",
    "for b in recHitBranches:\n",
    "    arr = ak.to_numpy(ak.flatten(data[b])).reshape(-1,MAX_HITS)  # (n_tracks, MAX_HITS)\n",
    "    recHitFeaturesList.append(arr)\n",
    "\n",
    "recHitFeatures = np.stack(recHitFeaturesList, axis=2)  # (n_tracks, MAX_HITS, n_features)\n",
    "\n",
    "recoPixelTrackList = []\n",
    "for b in recoPixelTrackBranches:\n",
    "    arr = ak.to_numpy(ak.flatten(data[b]))  # (n_tracks,)\n",
    "    recoPixelTrackList.append(arr)\n",
    "\n",
    "genPartList = []\n",
    "for b in genPartBranches:\n",
    "    arr = ak.to_numpy(data[b])  # (n_tracks,)\n",
    "    genPartList.append(arr)\n",
    "\n",
    "recoPixelTrackFeatures = np.stack(recoPixelTrackList[2:], axis=1)  # (n_tracks, n_features)\n",
    "recoPixelTrackLabels = np.array(recoPixelTrackList[0])\n",
    "recoPixelTrackIsHighPurity = np.array(recoPixelTrackList[1])\n",
    "recoPixelTrackFeatures_names = recoPixelTrackBranches[2:]  # skip 'hltPixelTrack_matched and IsHP' (label)\n",
    "genPart = np.array(genPartList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd04b0b-e99b-4709-9fa8-b22a23dd7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recHitFeatures: \", recHitFeatures.shape)\n",
    "print(\"recoPixelTrackFeatures: \", recoPixelTrackFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a0b51-0c79-4eb0-a26a-eea8be81a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds       = TrackDatasetFromFile(PREPROCESS_PATH)\n",
    "train_ds = TrackDatasetFromFile(PREPROCESS_PATH_TRAIN)\n",
    "val_ds   = TrackDatasetFromFile(PREPROCESS_PATH_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a1ef4-5bb8-4a35-a8ea-6aed19258c1b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bd98b-9ea7-46b7-b919-96ac4c861db6",
   "metadata": {},
   "source": [
    "### RecoPixelTracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998743f-049d-4e2f-a1dc-d6f9cfdb57e4",
   "metadata": {},
   "source": [
    "Inspect the properties of recoPixelTrack features to look for potential problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2491b54-b722-47c6-a580-5a3bb1cc4540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute feature statistics\n",
    "summary = summarize_features(recoPixelTrackFeatures, recoPixelTrackFeatures_names)\n",
    "summary_df = print_summary_table(summary, sort_by=\"skew\", top=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eacfc-6721-4195-b482-6e47e5d1e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = flag_outliers(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13729bf-267d-4778-a7c6-3282d9ab8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distributions(\n",
    "    X_ref=recoPixelTrackFeatures,\n",
    "    feature_names=recoPixelTrackFeatures_names,\n",
    "    y=recoPixelTrackLabels,\n",
    "    labels=(\"Original recoTrack Features\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf7509-a90d-4292-9f8a-09e82552a8f3",
   "metadata": {},
   "source": [
    "Apply clipping and log transformation where needed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cd865-a9dc-46c3-9cbb-a962ac3a5e5e",
   "metadata": {},
   "source": [
    "### RecHits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c12415-3cb6-454b-abca-91da8f29a45a",
   "metadata": {},
   "source": [
    "## Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75916b8-63ed-4da2-8735-4ee5b5c9ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    # --- Core datasets ---\n",
    "    \"recHitFeatures\": torch.tensor(recHitFeatures, dtype=torch.float32),\n",
    "    \"isRecHit\": ds.mask,\n",
    "    \"recoPixelTrackFeatures\": torch.tensor(recoPixelTrackFeatures, dtype=torch.float32),\n",
    "    \"labels\": ds.labels,\n",
    "    \"isHighPurity\": ds.isHighPurity,\n",
    "\n",
    "    # --- Normalization stats ---\n",
    "    \"recHit_mean\": ds.recHit_mean,\n",
    "    \"recHit_std\": ds.recHit_std,\n",
    "    \"recoPixelTrack_mean\": ds.recoPixelTrack_mean,\n",
    "    \"recoPixelTrack_std\": ds.recoPixelTrack_std,\n",
    "    \n",
    "    # --- Metadata ---\n",
    "    \"recHitBranches\": ds.recHitBranches,\n",
    "    \"recoPixelTrackBranches\": ds.recoPixelTrackBranches,  # exclude label and isHP\n",
    "    \"MAX_HITS\": ds.MAX_HITS,\n",
    "    \"EPSILON\": ds.EPSILON,\n",
    "    \"LOW_PERCENTILE\": ds.LOW_PERCENTILE,\n",
    "    \"HIGH_PERCENTILE\": ds.HIGH_PERCENTILE,\n",
    "    \"log_vars\": ds.log_vars,\n",
    "    \"clip_vars\": ds.clip_vars,\n",
    "    \"log_recHit_vars\": ds.log_recHit_vars,\n",
    "    \"do_log_hit\": ds.do_log_hit,\n",
    "    \"clip_min_hit\": ds.clip_min_hit,\n",
    "    \"clip_max_hit\": ds.clip_max_hit,\n",
    "    \"do_log_track\": ds.do_log_track,\n",
    "    \"clip_min_track\": ds.clip_min_track,\n",
    "    \"clip_max_track\": ds.clip_max_track\n",
    "}\n",
    "\n",
    "torch.save(save_dict, OUTPUT_PATH)\n",
    "print(f\"✅ Saved preprocessed dataset and parameters to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9f2af-8129-4565-8ffc-035d9fc81aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.2\n",
    "dataset_len = len(save_dict[\"labels\"])\n",
    "val_len = int(dataset_len * val_fraction)\n",
    "train_len = dataset_len - val_len\n",
    "\n",
    "indices = torch.randperm(dataset_len, generator=torch.Generator().manual_seed(42))\n",
    "train_idx, val_idx = indices[:train_len], indices[train_len:]\n",
    "\n",
    "def subset_dict(save_dict, indices):\n",
    "    subset = {}\n",
    "    # Only split the core dataset tensors\n",
    "    for key in [\"recHitFeatures\", \"isRecHit\", \"recoPixelTrackFeatures\", \"labels\", \"isHighPurity\"]:\n",
    "        subset[key] = save_dict[key][indices]\n",
    "    \n",
    "    # Copy metadata and normalization stats as-is\n",
    "    for key in [\"recHit_mean\", \"recHit_std\", \"recoPixelTrack_mean\", \"recoPixelTrack_std\",\n",
    "                \"recHitBranches\", \"recoPixelTrackBranches\", \"MAX_HITS\", \"EPSILON\",\n",
    "                \"LOW_PERCENTILE\", \"HIGH_PERCENTILE\", \"log_vars\", \"clip_vars\", \"log_recHit_vars\", \n",
    "                \"do_log_hit\", \"clip_min_hit\", \"clip_max_hit\", \"do_log_track\", \"clip_min_track\", \"clip_max_track\"]:\n",
    "        subset[key] = save_dict[key]\n",
    "    \n",
    "    return subset\n",
    "\n",
    "train_dict = subset_dict(save_dict, train_idx)\n",
    "val_dict = subset_dict(save_dict, val_idx)\n",
    "\n",
    "torch.save(train_dict, OUTPUT_PATH_TRAIN)\n",
    "torch.save(val_dict, OUTPUT_PATH_VAL)\n",
    "print(f\"✅ Saved train and validation datasets with metadata\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
